# Notes on Machine Learning and Medical Research Papers

A collection of research paper summaries, on machine learning and medical (brain computer interface and vision). ML papers are mainly on solving computer vision or sequential problems, and medical papers are focusing on vision problems. 

Papers are sorted by topics and tags. Go to the [Issues](https://github.com/jinglescode/papers/issues) tab to browse, search and filter research papers. 

## Table of Contents

**[Machine Learning](#machine-learning)**

- [Autoencoder](#autoencoder)
- [Computer Vision](#computer-vision)
- [Sequential](#sequential)
- [Sequential: Transformer](#sequential)

**[Medical](#medical)**
- [Brain computer interface](#brain-computer-interface)
- [Vision](#vision)

---

# Machine Learning

## Autoencoder

- [Machine translation of cortical activity to text with an encoder–decoder framework](https://github.com/jinglescode/ml-papers/issues/15)
- [Speech synthesis from neural decoding of spoken sentences](https://github.com/jinglescode/ml-papers/issues/16)
- [Conv-tasnet: Surpassing ideal time–frequency magnitude masking for speech separation](https://github.com/jinglescode/ml-papers/issues/18)
- [Tacotron: Towards End-to-End Speech Synthesis](https://github.com/jinglescode/papers/issues/24)
- [Wave-Tacotron: Spectrogram-free end-to-end text-to-speech synthesis](https://github.com/jinglescode/papers/issues/25)
- [Pay Less Attention with Lightweight and Dynamic Convolutions](https://github.com/jinglescode/papers/issues/28)

## Computer vision

- [Interpretable and Fine-Grained Visual Explanations for Convolutional Neural Networks](https://github.com/jinglescode/ml-papers/issues/1)
- [Stand-Alone Self-Attention in Vision Models](https://github.com/jinglescode/ml-papers/issues/21)
- [On the relationship between self-attention and convolutional layers](https://github.com/jinglescode/papers/issues/22)
- [Dynamic Convolution: Attention over Convolution Kernels](https://github.com/jinglescode/papers/issues/27)
- [Dynamic Group Convolution for Accelerating Convolutional Neural Networks](https://github.com/jinglescode/papers/issues/29)
- [An image is worth 16x16 words: Transformers for image recognition at scale](https://github.com/jinglescode/papers/issues/50)
- [End-to-End Video Instance Segmentation with Transformers](https://github.com/jinglescode/papers/issues/60)
- [Deep learning-enabled medical computer vision](https://github.com/jinglescode/papers/issues/63)
- [Bottleneck Transformers for Visual Recognition](https://github.com/jinglescode/papers/issues/64)

## Sequential

- [An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling](https://github.com/jinglescode/ml-papers/issues/14)
- [Wavenet: A generative model for raw audio](https://github.com/jinglescode/ml-papers/issues/17)
- [Conv-tasnet: Surpassing ideal time–frequency magnitude masking for speech separation](https://github.com/jinglescode/ml-papers/issues/18)
- [Convolutional Sequence to Sequence Learning](https://github.com/jinglescode/ml-papers/issues/19)
- [Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions](https://github.com/jinglescode/ml-papers/issues/20)
- [Parallel wavenet: Fast high-fidelity speech synthesis](https://github.com/jinglescode/papers/issues/23)
- [Tacotron: Towards End-to-End Speech Synthesis](https://github.com/jinglescode/papers/issues/24)
- [Wave-Tacotron: Spectrogram-free end-to-end text-to-speech synthesis](https://github.com/jinglescode/papers/issues/25)
- [Location-Relative Attention Mechanisms For Robust Long-Form Speech Synthesis](https://github.com/jinglescode/papers/issues/26)
- [Pay Less Attention with Lightweight and Dynamic Convolutions](https://github.com/jinglescode/papers/issues/28)
- [Learning representations from EEG with deep recurrent-convolutional neural networks](https://github.com/jinglescode/papers/issues/30)
- [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://github.com/jinglescode/papers/issues/32)
- [Improved Noisy Student Training for Automatic Speech Recognition](https://github.com/jinglescode/papers/issues/33)
- [Visual to Sound: Generating Natural Sound for Videos in the Wild](https://github.com/jinglescode/papers/issues/36)
- [SampleRNN: An unconditional end-to-end neural audio generation model](https://github.com/jinglescode/papers/issues/37)
- [Generating Visually Aligned Sound from Videos](https://github.com/jinglescode/papers/issues/38)

### Sequential: Transformer

- [Transformer-xl: Attentive language models beyond a fixed-length context](https://github.com/jinglescode/papers/issues/39)
- [Compressive transformers for long-range sequence modelling](https://github.com/jinglescode/papers/issues/40)
- [Reformer: The efficient transformer](https://github.com/jinglescode/papers/issues/41)
- [Music transformer: Generating music with long-term structure](https://github.com/jinglescode/papers/issues/42)
- [Conformer: Convolution-augmented Transformer for Speech Recognition](https://github.com/jinglescode/papers/issues/43)
- [Transformer transducer: A streamable speech recognition model with transformer encoders and rnn-t loss](https://github.com/jinglescode/papers/issues/44)
- [Rethinking Attention with Performers](https://github.com/jinglescode/papers/issues/45)
- [Linformer: Self-Attention with Linear Complexity](https://github.com/jinglescode/papers/issues/46)
- [Transformers are rnns: Fast autoregressive transformers with linear attention](https://github.com/jinglescode/papers/issues/49)
- [An image is worth 16x16 words: Transformers for image recognition at scale](https://github.com/jinglescode/papers/issues/50)
- [Big bird: Transformers for longer sequences](https://github.com/jinglescode/papers/issues/51)
- [Long Range Arena : A Benchmark for Efficient Transformers](https://github.com/jinglescode/papers/issues/53)
- [Earthquake transformer—an attentive deep-learning model for simultaneous earthquake detection and phase picking](https://github.com/jinglescode/papers/issues/54)
- [O(n) Connections are Expressive Enough: Universal Approximability of Sparse Transformers](https://github.com/jinglescode/papers/issues/55)
- [Are Transformers universal approximators of sequence-to-sequence functions?](https://github.com/jinglescode/papers/issues/56)
- [Fast Transformers with Clustered Attention](https://github.com/jinglescode/papers/issues/58)
- [Transformers with convolutional context for ASR](https://github.com/jinglescode/papers/issues/59)
- [Exploring Transformers for Large-Scale Speech Recognition](https://github.com/jinglescode/papers/issues/61)
- [Transformers without Tears: Improving the Normalization of Self-Attention](https://github.com/jinglescode/papers/issues/62)
- [Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting](https://github.com/jinglescode/papers/issues/66)

# Medical

## Brain computer interface

- [Learning across multi-stimulus enhances target recognition methods in SSVEP-based BCIs](https://github.com/jinglescode/ml-papers/issues/6)
- [Deep Learning-based Classification for Brain-Computer Interfaces](https://github.com/jinglescode/ml-papers/issues/12)
- [Learning representations from EEG with deep recurrent-convolutional neural networks](https://github.com/jinglescode/papers/issues/30)
- [Retinotopic and topographic analyses with gaze restriction for steady-state visual evoked potentials](https://github.com/jinglescode/papers/issues/31)
- [Steady-state visually evoked potentials: Focus on essential paradigms and future perspectives](https://github.com/jinglescode/papers/issues/34)
- [Filter bank canonical correlation analysis for implementing a high-speed SSVEP-based brain–computer interface](https://github.com/jinglescode/papers/issues/48)
- [Methods of EEG Signal Features Extraction Using Linear Analysis in Frequency and Time-Frequency Domains](https://github.com/jinglescode/papers/issues/52)
- [MI-EEGNET: A novel Convolutional Neural Network for motor imagery classification](https://github.com/jinglescode/papers/issues/57)

## Vision

- [A comparison of covert and overt attention as a control option in a steady-state visual evoked potential-based brain computer interface](https://github.com/jinglescode/ml-papers/issues/2)
- [Neural Differences between Covert and Overt Attention Studied using EEG with Simultaneous Remote Eye Tracking](https://github.com/jinglescode/ml-papers/issues/3)
- [Visual field testing for glaucoma – a practical guide](https://github.com/jinglescode/ml-papers/issues/4)
- [Walking enhances peripheral visual processing in humans](https://github.com/jinglescode/ml-papers/issues/5)
- [The steady-state visual evoked potential in vision research: A review](https://github.com/jinglescode/ml-papers/issues/7)
- [Multifocal Visual Evoked Potential (mfVEP) and Pattern-Reversal Visual Evoked Potential Changes in Patients with Visual Pathway Disorders: A Case Series](https://github.com/jinglescode/ml-papers/issues/8)
- [Study for Analysis of the Multifocal Visual Evoked Potential](https://github.com/jinglescode/ml-papers/issues/9)
- [Multifocal visual evoked potentials for quantifying optic nerve dysfunction in patients with optic disc drusen](https://github.com/jinglescode/ml-papers/issues/10)
- [Steady-state multifocal visual evoked potential (ssmfVEP) using dartboard stimulation as a possible tool for objective visual field assessment](https://github.com/jinglescode/ml-papers/issues/11)
- [A comparison of covert and overt attention as a control option in a steady-state visual evoked potential-based brain computer interface](https://github.com/jinglescode/ml-papers/issues/13)
- [A Review of Deep Learning for Screening, Diagnosis, and Detection of Glaucoma Progression](https://github.com/jinglescode/papers/issues/35)
- [Objective visual field determination in forensic ophthalmology with an optimized 4-channel multifocal VEP perimetry system: a case report of a patient with retinitis pigmentosa](https://github.com/jinglescode/papers/issues/65)
- [Selective attention to stimulus location modulates the steady-state visual evoked potential](https://github.com/jinglescode/papers/issues/67)
